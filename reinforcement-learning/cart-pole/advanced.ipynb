{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Reinforcement learning agent in the Cart Pole environment\n",
    "==="
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23c03779b2a1a5c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Environment description\n",
    "---\n",
    "\n",
    "Actions: ndarray (1,)\n",
    " - {0, 1}: In which direction (0 = left, 1 = right) to push the cart.\n",
    "\n",
    "Observation: ndarray (4,)\n",
    " - \\[cart position, cart velocity, pole angle, pole angular velocity\\]\n",
    " \n",
    "Reward: float\n",
    " - Reward is for every step taken, including the termination step.\n",
    " \n",
    "Termination and truncation: bool\n",
    " - Pole Angle is more than ±12°\n",
    " - Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\n",
    " - Episode length is greater than 500"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a227dd4386c39e84"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Disable plot axes and ticks:\n",
    "plt.rcParams.update({\n",
    "    'axes.spines.top': False, \n",
    "    'axes.spines.right': False, \n",
    "    'axes.spines.bottom': False, \n",
    "    'axes.spines.left': False, \n",
    "    'xtick.bottom': False, \n",
    "    'xtick.labelbottom': False, \n",
    "    'ytick.labelleft': False, \n",
    "    'ytick.left': False\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T15:28:00.198232Z",
     "start_time": "2024-02-01T15:27:59.748297Z"
    }
   },
   "id": "c69f9f38e669d12c",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e962668f69b161cf"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-01T15:28:00.770207Z",
     "start_time": "2024-02-01T15:28:00.199575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "environment = gym.make('CartPole-v1', render_mode=\"rgb_array\")\n",
    "\n",
    "_ = environment.reset()\n",
    "_ = plt.imshow(environment.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6b879b884f78c2d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, inputs=4, actions=2, hidden=False, neurons=64):\n",
    "        \"\"\"\n",
    "        Agent for reinforcement learning.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : int, optional\n",
    "            Number of inputs.\n",
    "        actions : int, optional\n",
    "            Number of actions.\n",
    "        hidden : int or False, optional\n",
    "            Number of hidden layers.\n",
    "        neurons : int, optional\n",
    "            Number of neurons between layers.\n",
    "        \"\"\"\n",
    "        super(Agent, self).__init__()\n",
    "        self.hidden = hidden\n",
    "        \n",
    "        self.layer_in = nn.Linear(inputs, neurons)\n",
    "        \n",
    "        if self.hidden:\n",
    "            for i in range(self.hidden):\n",
    "                setattr(self, f\"layer_{i+1}\", nn.Linear(neurons, neurons))\n",
    "            \n",
    "        self.layer_out = nn.Linear(neurons, actions)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : numpy.ndarray or torch.Tensor\n",
    "            Observation state.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        output : torch.Tensor\n",
    "            Action probabilities.\n",
    "        \"\"\"\n",
    "        _output = torch.relu(self.layer_in(x))\n",
    "        \n",
    "        if self.hidden:\n",
    "            for i in range(self.hidden):\n",
    "                _output = torch.relu(getattr(self, f\"layer_{i+1}\")(_output))\n",
    "            \n",
    "        if self.layer_out.out_features > 1:\n",
    "            output = torch.log_softmax(self.layer_out(_output), dim=-1)\n",
    "        else:\n",
    "            output = torch.sigmoid(self.layer_out(_output))\n",
    "        \n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T15:28:01.671662Z",
     "start_time": "2024-02-01T15:28:00.771636Z"
    }
   },
   "id": "b245eb61c9fd0614",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additions\n",
    "\n",
    "Asking GitHub Copilot Chat: \"Are there any additional steps I can take to speed up training?\"\n",
    "\n",
    "It answered that experience replay is a good idea – and gave me the following code. I also \n",
    "implemented a loss function using the memory and Q-learning."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26d27b964d990e8c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, transition):\n",
    "        self.memory.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T15:28:01.671851Z",
     "start_time": "2024-02-01T15:28:01.658906Z"
    }
   },
   "id": "626eae4d14c4c7bf",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7ade8fc0157ed95"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agent '2-hidden-128-neurons'...\n",
      "Agent '2-hidden-128-neurons' trained.\n"
     ]
    }
   ],
   "source": [
    "EPISODES = 1000\n",
    "BATCH_SIZE = 64\n",
    "DISCOUNT = 0.95\n",
    "\n",
    "agents = {\"2-hidden-128-neurons\": Agent(inputs=4, actions=2, hidden=2, neurons=128)}\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "for description, agent in agents.items():\n",
    "    \n",
    "    print(f\"Training agent '{description}'...\")\n",
    "    \n",
    "    optimizer = torch.optim.RMSprop(agent.parameters(), \n",
    "                                    lr=0.00025, eps=0.01)\n",
    "    \n",
    "    for episode in range(EPISODES):\n",
    "        \n",
    "        observation, info = environment.reset()\n",
    "        observation = torch.tensor(observation, dtype=torch.float32)\n",
    "        \n",
    "        for step in range(1000):\n",
    "            \n",
    "            actions = agent(observation)\n",
    "\n",
    "            if agent.layer_out.out_features > 1:\n",
    "                action = actions.argmax().item()\n",
    "            else:\n",
    "                action = int(actions.round().item())\n",
    "            \n",
    "            next_observation, reward, terminated, truncated, _ = environment.step(action)\n",
    "            next_observation = torch.tensor(next_observation, dtype=torch.float32)\n",
    "            finished = terminated or truncated\n",
    "            \n",
    "            memory.push((observation, action, reward, next_observation, finished))\n",
    "            observation = next_observation\n",
    "            \n",
    "            if len(memory) < BATCH_SIZE:\n",
    "                continue\n",
    "                \n",
    "            # Sample a batch of transitions\n",
    "            transitions = memory.sample(BATCH_SIZE)\n",
    "            \n",
    "            # Unpack transitions\n",
    "            state_batch, action_batch, reward_batch, next_state_batch, done_batch = zip(*transitions)\n",
    "            \n",
    "            # Convert to tensors\n",
    "            state_batch = torch.stack(state_batch)\n",
    "            action_batch = torch.tensor(action_batch, dtype=torch.long)\n",
    "            reward_batch = torch.tensor(reward_batch, dtype=torch.int)\n",
    "            next_state_batch = torch.stack(next_state_batch)\n",
    "            done_batch = torch.tensor(done_batch, dtype=torch.bool)\n",
    "            \n",
    "            # Compute Q-values for the current and next states as well as the expected Q-values\n",
    "            state_action_values = agent(state_batch).gather(1, action_batch.unsqueeze(-1)).squeeze(-1)\n",
    "            next_state_values = agent(next_state_batch).max(1)[0].detach()\n",
    "            expected_state_action_values = reward_batch + (next_state_values * DISCOUNT * \n",
    "                                                           ~done_batch)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = loss_function(state_action_values, expected_state_action_values)\n",
    "            \n",
    "            # Backpropagate the loss and update the weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if finished:\n",
    "                observation, _ = environment.reset()\n",
    "                observation = torch.tensor(observation, dtype=torch.float32)\n",
    "                \n",
    "    print(f\"Agent '{description}' trained.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T15:59:29.243521Z",
     "start_time": "2024-02-01T15:49:50.288921Z"
    }
   },
   "id": "cb9003cfbc25239e",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the agent to play the game and save the frames.\n",
    "\n",
    "observation, info = environment.reset()\n",
    "\n",
    "for timestep in range(1000):\n",
    "    \n",
    "    observation = torch.tensor(observation, dtype=torch.float32)\n",
    "    actions = agents['2-hidden-128-neurons'](observation)\n",
    "    action = actions.argmax().item()\n",
    "    \n",
    "    print(action)\n",
    "    \n",
    "    observation, reward, terminated, truncated, _ = environment.step(action)\n",
    "    \n",
    "    _ = plt.imshow(environment.render())\n",
    "    plt.savefig(f\"./images/cart-pole/{timestep}.png\")\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T16:00:33.715474Z",
     "start_time": "2024-02-01T16:00:32.690078Z"
    }
   },
   "id": "c6ebbde1d8daa55b",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "environment.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbf42b7cc327e299"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sources\n",
    "\n",
    "https://gymnasium.farama.org/content/basic_usage/\n",
    "\n",
    "https://gymnasium.farama.org/environments/classic_control/cart_pole/\n",
    "\n",
    "https://ieeexplore.ieee.org/document/6313077"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf92ff7a0b0251bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
