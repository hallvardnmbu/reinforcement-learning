{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Visualise the pre-trained agent in action\n",
    "\n",
    "Modify the path to the weights and run the notebook."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3d8465ecb86eca7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "WEIGHTS = './weights/weights-[NUMBER]'  # NB: without '.pth'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e285c80c5e2766a4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio\n",
    "import gymnasium as gym\n",
    "\n",
    "from upload.agent import VisionDeepQ"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "network = {\n",
    "    \"input_channels\": 1, \"outputs\": 5,\n",
    "    \"channels\": [32, 64, 64],\n",
    "    \"kernels\": [5, 3, 3],\n",
    "    \"strides\": [3, 2, 1],\n",
    "    \"nodes\": [64]\n",
    "}\n",
    "optimizer = {\n",
    "    \"optimizer\": torch.optim.AdamW,\n",
    "    \"lr\": 0.001,\n",
    "    \"hyperparameters\": {}\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16867687f37ddbca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "value_agent = VisionDeepQ(\n",
    "    network=network, optimizer=optimizer,\n",
    ")\n",
    "\n",
    "weights = torch.load(f'{WEIGHTS}.pth', map_location=torch.device('cpu'))\n",
    "value_agent.load_state_dict(weights)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "545e1bc3efb30329",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "environment = gym.make('ALE/Tetris-v5', render_mode=\"rgb_array\",\n",
    "                       obs_type=\"grayscale\", frameskip=4, repeat_action_probability=0.25)\n",
    "environment.metadata[\"render_fps\"] = 30"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7a46dd5b36d0c4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "state = torch.tensor(environment.reset()[0], dtype=torch.float32).view((1, 1, 210, 160))\n",
    "\n",
    "images = []\n",
    "TERMINATED = TRUNCATED = False\n",
    "while not (TERMINATED or TRUNCATED):\n",
    "    action = value_agent(state).argmax(1).item()\n",
    "\n",
    "    state, reward, TERMINATED, TRUNCATED, _ = environment.step(action)\n",
    "    state = torch.tensor(state, dtype=torch.float32).view((1, 1, 210, 160))\n",
    "\n",
    "    images.append(environment.render())\n",
    "_ = imageio.mimsave(f'./{WEIGHTS}.gif', images, duration=25)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2ba42f6d9ca3e92",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
